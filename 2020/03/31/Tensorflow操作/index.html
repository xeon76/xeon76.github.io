<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://xeon76.github.io').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.6.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="Tensorflow基础操作创建tensortf.convert_to_tensor()  将其他类型数据转换为tensor类型1234a &#x3D; np.arange(5)aa &#x3D; tf.convert_to_tensor(a,dtype&#x3D;tf.int32)   #可以指定类型的tf.cast(aa,dtype&#x3D;tf.float32)   #数据类型转换 numpy类型转换为tensor类型">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow操作">
<meta property="og:url" content="https://xeon76.github.io/2020/03/31/Tensorflow%E6%93%8D%E4%BD%9C/index.html">
<meta property="og:site_name" content="小强的秘密花园">
<meta property="og:description" content="Tensorflow基础操作创建tensortf.convert_to_tensor()  将其他类型数据转换为tensor类型1234a &#x3D; np.arange(5)aa &#x3D; tf.convert_to_tensor(a,dtype&#x3D;tf.int32)   #可以指定类型的tf.cast(aa,dtype&#x3D;tf.float32)   #数据类型转换 numpy类型转换为tensor类型">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-03-31T15:44:43.000Z">
<meta property="article:modified_time" content="2020-06-26T12:14:48.179Z">
<meta property="article:author" content="徐志强">
<meta property="article:tag" content="Tensorflow">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://xeon76.github.io/2020/03/31/Tensorflow%E6%93%8D%E4%BD%9C/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>Tensorflow操作 | 小强的秘密花园</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">小强的秘密花园</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xeon76.github.io/2020/03/31/Tensorflow%E6%93%8D%E4%BD%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://raw.githubusercontent.com/xeon76/picture/xeon76-patch-1/nier.jpg">
      <meta itemprop="name" content="徐志强">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小强的秘密花园">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Tensorflow操作
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-31 23:44:43" itemprop="dateCreated datePublished" datetime="2020-03-31T23:44:43+08:00">2020-03-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-06-26 20:14:48" itemprop="dateModified" datetime="2020-06-26T20:14:48+08:00">2020-06-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tensorflow/" itemprop="url" rel="index">
                    <span itemprop="name">Tensorflow</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Tensorflow基础操作"><a href="#Tensorflow基础操作" class="headerlink" title="Tensorflow基础操作"></a>Tensorflow基础操作</h1><h2 id="创建tensor"><a href="#创建tensor" class="headerlink" title="创建tensor"></a>创建tensor</h2><h3 id="tf-convert-to-tensor-将其他类型数据转换为tensor类型"><a href="#tf-convert-to-tensor-将其他类型数据转换为tensor类型" class="headerlink" title="tf.convert_to_tensor()  将其他类型数据转换为tensor类型"></a>tf.convert_to_tensor()  将其他类型数据转换为tensor类型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">5</span>)</span><br><span class="line">aa = tf.convert_to_tensor(a,dtype=tf.int32)   <span class="comment">#可以指定类型的</span></span><br><span class="line"></span><br><span class="line">tf.cast(aa,dtype=tf.float32)   <span class="comment">#数据类型转换</span></span><br></pre></td></tr></table></figure>
<p>numpy类型转换为tensor类型</p>
<a id="more"></a>

<h3 id="tf-zeros"><a href="#tf-zeros" class="headerlink" title="tf.zeros([])"></a>tf.zeros([])</h3><p>生成形状为[]的全零数组 </p>
<h3 id="tf-zeros-like-a"><a href="#tf-zeros-like-a" class="headerlink" title="tf.zeros_like(a)"></a>tf.zeros_like(a)</h3><p>生成形状和a相同的全零数组</p>
<h3 id="tf-ones"><a href="#tf-ones" class="headerlink" title="tf.ones([])"></a>tf.ones([])</h3><p>生成形状为[]的全一数组</p>
<h3 id="tf-ones-like-a"><a href="#tf-ones-like-a" class="headerlink" title="tf.ones_like(a)"></a>tf.ones_like(a)</h3><p>生成形状和a相同的全一数组</p>
<h3 id="tf-fill-a"><a href="#tf-fill-a" class="headerlink" title="tf.fill([],a)"></a>tf.fill([],a)</h3><p>前面是创建的形状，后面a是填充的数字</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.fill([<span class="number">2</span>,<span class="number">2</span>],<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h3 id="tf-random-normal-mean-stddev-正太分布"><a href="#tf-random-normal-mean-stddev-正太分布" class="headerlink" title="tf.random.normal([],mean=,stddev=)  正太分布"></a>tf.random.normal([],mean=,stddev=)  正太分布</h3><p>正太分布,默认0，1分布 mean均值,stddev方差</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.random.normal([<span class="number">2</span>,<span class="number">2</span>],mean=<span class="number">1</span>,stddev=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h3 id="tf-random-truncated-normal-mean-stddev"><a href="#tf-random-truncated-normal-mean-stddev" class="headerlink" title="tf.random.truncated_normal([],mean=,stddev=)"></a>tf.random.truncated_normal([],mean=,stddev=)</h3><p>字面意思是截断的，而截断的标准是2倍的stddev.<br>举例，当输入参数mean = 0 ， stddev =1时，<br>使用tf.truncated_normal的输出是不可能出现[-2,2]以外的点的.</p>
<h3 id="tf-random-uniform-minval-maxval"><a href="#tf-random-uniform-minval-maxval" class="headerlink" title="tf.random.uniform([],minval=,maxval=)"></a>tf.random.uniform([],minval=,maxval=)</h3><p>均匀分布 minval最小值 maxval最大值</p>
<h3 id="tf-random-shuttle"><a href="#tf-random-shuttle" class="headerlink" title="tf.random.shuttle([])"></a>tf.random.shuttle([])</h3><p>随机打散 这边[]里面放的是需要打散的序列，上面那些放的是打散的形状</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">idx = tf.range(<span class="number">10</span>)</span><br><span class="line">idx = tf.random.shuttle(idx)</span><br><span class="line"></span><br><span class="line">输出：tf.Tensor: id:<span class="number">67</span>,shape=(<span class="number">10</span>,),dtype=int32,numpy=array([<span class="number">2</span>,<span class="number">1</span>,<span class="number">9</span>,<span class="number">3</span>,<span class="number">8</span>,<span class="number">7</span>,<span class="number">0</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">6</span>])</span><br></pre></td></tr></table></figure>

<h3 id="tf-gather-a-idx"><a href="#tf-gather-a-idx" class="headerlink" title="tf.gather(a,idx)"></a>tf.gather(a,idx)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.uniform([<span class="number">10</span>],maxval=<span class="number">10</span>,dtype=tf.int32)</span><br><span class="line">a = tf.gather(a,idx)    <span class="comment">#将a用idx的顺序打散</span></span><br></pre></td></tr></table></figure>

<h3 id="tf-one-hot-y-depth"><a href="#tf-one-hot-y-depth" class="headerlink" title="tf.one_hot(y,depth=)"></a>tf.one_hot(y,depth=)</h3><p>将y转换为深度为depth的独热编码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y = tf.range(<span class="number">2</span>)</span><br><span class="line">y = tf.one_hot(y,depth=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">[[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]]</span><br></pre></td></tr></table></figure>

<h3 id="tf-keras-losses-mse-y-out"><a href="#tf-keras-losses-mse-y-out" class="headerlink" title="tf.keras.losses.mse(y,out)"></a>tf.keras.losses.mse(y,out)</h3><p>求y与out之间的均方差，要注意输出，具体看PPT</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">out = tf.random.uniform([<span class="number">4</span>,<span class="number">10</span>])</span><br><span class="line">y = tf.range(<span class="number">4</span>)</span><br><span class="line">y =tf.one_hot(y,depth=<span class="number">10</span>)</span><br><span class="line">loss = tf.keras.losses.mse(y,out)    <span class="comment"># 这边y和out的形状要匹配</span></span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">[<span class="number">0.37688</span>,<span class="number">0.24342</span>,<span class="number">0.53423</span>,<span class="number">0.23131</span>]   <span class="comment">#注意这边的形状</span></span><br></pre></td></tr></table></figure>

<h3 id="tf-reduce-mean"><a href="#tf-reduce-mean" class="headerlink" title="tf.reduce_mean()"></a>tf.reduce_mean()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">loss = tf.reduce_mean(loss)     <span class="comment">#这边括号里面的loss是上面的loss，这个函数好像可以指定维度求均值，axis= 即可</span></span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">上面四个数的均值</span><br></pre></td></tr></table></figure>

<h3 id="net-layers-Dense-10"><a href="#net-layers-Dense-10" class="headerlink" title="net.layers.Dense(10)"></a>net.layers.Dense(10)</h3><p>创建10个神经元节点，在输入层之后</p>
<h3 id="net-build"><a href="#net-build" class="headerlink" title="net.build([])"></a>net.build([])</h3><p>[]为输入神经元数据的形状</p>
<h3 id="net-kernel"><a href="#net-kernel" class="headerlink" title="net.kernel"></a>net.kernel</h3><p>w@x+b中的w</p>
<h3 id="net-bias"><a href="#net-bias" class="headerlink" title="net.bias"></a>net.bias</h3><p>w@x+b中的b</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">net = layers.Dense(<span class="number">10</span>)   <span class="comment">#上面两行通常放在一起</span></span><br><span class="line">net.build(<span class="number">4</span>,<span class="number">8</span>)   <span class="comment">#输入数据形状是（4，8）的</span></span><br><span class="line">net.kernel   <span class="comment">#形状（8，10）</span></span><br><span class="line">net.bias     <span class="comment">#形状（10，）</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">784</span>])</span><br><span class="line">net = layers.Dense(<span class="number">10</span>)</span><br><span class="line">net.build(<span class="number">4</span>,<span class="number">784</span>)</span><br><span class="line">net(x).shape        <span class="comment">#[4,10]</span></span><br><span class="line">net.kernel.shape    <span class="comment">#[784,10]</span></span><br><span class="line">net.bias.shape      <span class="comment">#[10]</span></span><br></pre></td></tr></table></figure>

<h2 id="索引和切片"><a href="#索引和切片" class="headerlink" title="索引和切片"></a>索引和切片</h2><h3 id="普通用法"><a href="#普通用法" class="headerlink" title="普通用法"></a>普通用法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">a = tf.ones([<span class="number">1</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">3</span>])</span><br><span class="line">a[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">a[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">a[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>][<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">array([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">	[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">	[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">	[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">	[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">array([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">array([<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.normal([<span class="number">4</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">3</span>])</span><br><span class="line">a[<span class="number">1</span>].shape        <span class="comment">#[28,28,3]</span></span><br><span class="line">a[<span class="number">1</span>,<span class="number">2</span>].shape      <span class="comment">#[28,3]</span></span><br><span class="line">a[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>].shape    <span class="comment">#[3]</span></span><br><span class="line">a[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>].shape  <span class="comment">#[]</span></span><br></pre></td></tr></table></figure>
<h3 id="用法"><a href="#用法" class="headerlink" title=":用法"></a>:用法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = tf.range(<span class="number">10</span>)</span><br><span class="line">a[<span class="number">-1</span>:]           <span class="comment">#[9]</span></span><br><span class="line">a[<span class="number">-2</span>:]           <span class="comment">#[8,9]</span></span><br><span class="line">a[:<span class="number">2</span>]            <span class="comment">#[0,1]</span></span><br><span class="line">a[:<span class="number">-1</span>]           <span class="comment">#[0,1,2,3,4,5,6,7,8]</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a.shape          <span class="comment">#[4,8,28,3]</span></span><br><span class="line">a[<span class="number">0</span>].shape       <span class="comment">#[28,28,3]</span></span><br><span class="line">a[<span class="number">0</span>,:,:,:].shape <span class="comment">#[28,28,3]</span></span><br><span class="line">a[<span class="number">0</span>,<span class="number">1</span>,:,:].shape <span class="comment">#[28,3]</span></span><br><span class="line">a[:,:,:,<span class="number">0</span>].shape <span class="comment">#[4,28,28]</span></span><br><span class="line">a[:,<span class="number">0</span>,:,:].shape <span class="comment">#[4,28,3]</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a.shape                     <span class="comment">#[4,28,28,3]</span></span><br><span class="line">a[<span class="number">0</span>:<span class="number">2</span>,:,:,:].shape          <span class="comment">#[2,28,28,3]</span></span><br><span class="line">a[:,<span class="number">0</span>:<span class="number">28</span>:<span class="number">2</span>,<span class="number">0</span>:<span class="number">28</span>:<span class="number">2</span>,:].shape  <span class="comment">#[4,14,14,3]</span></span><br><span class="line">a[:,:<span class="number">14</span>,:<span class="number">14</span>,:].shape        <span class="comment">#[4,14,14,3]         </span></span><br><span class="line">a[:,<span class="number">14</span>:,<span class="number">14</span>:,:].shape        <span class="comment">#[4,14,14,3]</span></span><br><span class="line">a[:,::<span class="number">2</span>,::<span class="number">2</span>,:].shape        <span class="comment">#[4,14,14,3]     每两个取一个</span></span><br></pre></td></tr></table></figure>
<h3 id="：用法"><a href="#：用法" class="headerlink" title="：用法"></a>：用法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.range(<span class="number">4</span>)            <span class="comment">#[0,1,2,3]</span></span><br><span class="line">a[::<span class="number">-1</span>]                    <span class="comment">#[3,2,1,0]</span></span><br><span class="line">a[::<span class="number">-2</span>]                    <span class="comment">#[3,1]</span></span><br><span class="line">a[<span class="number">2</span>::<span class="number">-2</span>]                   <span class="comment">#[2,0]</span></span><br></pre></td></tr></table></figure>
<h3 id="…用法"><a href="#…用法" class="headerlink" title="…用法"></a>…用法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.normal([<span class="number">2</span>,<span class="number">4</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">3</span>])</span><br><span class="line">a[<span class="number">0</span>].shape            <span class="comment">#[4,28,28,3]</span></span><br><span class="line">a[<span class="number">0</span>,:,:,:,:].shape    <span class="comment">#[4,28,28,3]</span></span><br><span class="line">a[<span class="number">0</span>,...].shape        <span class="comment">#[4,28,28,3]</span></span><br><span class="line">a[:,:,:,:,<span class="number">0</span>].shape    <span class="comment">#[4,28,28,3]</span></span><br><span class="line">a[...,<span class="number">0</span>].shape        <span class="comment">#[4,28,28,3]</span></span><br><span class="line">a[<span class="number">0</span>,...,<span class="number">2</span>].shape      <span class="comment">#[4,28,28]</span></span><br><span class="line">a[<span class="number">1</span>,<span class="number">0</span>,...,<span class="number">0</span>].shape    <span class="comment">#[28,28]</span></span><br></pre></td></tr></table></figure>
<h3 id="tf-gather-a-axis-d-indices-b-c-选取第d个维度，然后把这个维度中的第b-c个vector抽取出来，只能对一个维度进行操作"><a href="#tf-gather-a-axis-d-indices-b-c-选取第d个维度，然后把这个维度中的第b-c个vector抽取出来，只能对一个维度进行操作" class="headerlink" title="tf.gather(a,axis=d,indices=[b,c]) 选取第d个维度，然后把这个维度中的第b,c个vector抽取出来，只能对一个维度进行操作"></a>tf.gather(a,axis=d,indices=[b,c]) 选取第d个维度，然后把这个维度中的第b,c个vector抽取出来，只能对一个维度进行操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a.shape       <span class="comment">#[4，28，8]</span></span><br><span class="line">tf.gather(a,axis=<span class="number">0</span>,indices=[<span class="number">2</span>,<span class="number">3</span>]).shape    <span class="comment">#[2,35,8]</span></span><br><span class="line">a[<span class="number">2</span>:<span class="number">4</span>].shape   <span class="comment">##[2,35,8]</span></span><br><span class="line">tf.gather(a,axis=<span class="number">0</span>,indics=[<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">0</span>]).shape <span class="comment">#[4,35,8]</span></span><br><span class="line">tf.gather(a,axis=<span class="number">1</span>,indices=[<span class="number">2</span>,<span class="number">3</span>,<span class="number">7</span>,<span class="number">9</span>,<span class="number">16</span>]).shape <span class="comment">#[4,5,8]</span></span><br><span class="line">tf.gather(a,axis=<span class="number">2</span>,indices=[<span class="number">2</span>,<span class="number">3</span>,<span class="number">7</span>]).shape  <span class="comment">#[4,35,3]</span></span><br></pre></td></tr></table></figure>

<h3 id="tf-gather-nd-a"><a href="#tf-gather-nd-a" class="headerlink" title="tf.gather_nd(a,[[],[],[]])"></a>tf.gather_nd(a,[[],[],[]])</h3><p>可以对多个维度进行操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a.shape         <span class="comment">#[4,35,8]</span></span><br><span class="line">tf.gather_nd(a,[<span class="number">0</span>]).shape  <span class="comment">#[35,8]</span></span><br><span class="line">tf.gather_nd(a,[<span class="number">0</span>,<span class="number">1</span>]).shape <span class="comment">#[8]</span></span><br><span class="line">tf.gather_nd(a,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]).shape  <span class="comment">#[]</span></span><br><span class="line">tf.gather_nd(a,[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]]).shape  <span class="comment">#[1]</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a.shape         <span class="comment">#[4,35,8]</span></span><br><span class="line">tf.gather_nd(a,[[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>]]).shape <span class="comment">#[2,8]</span></span><br><span class="line">tf.gather_nd(a,[[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>]]).shape  <span class="comment">#[3,8]</span></span><br><span class="line">tf.gather_nd(a,[[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]]).shape <span class="comment">#[3]          [1,2,3]</span></span><br><span class="line">tf.gather_nd(a,[[[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]]]).shape <span class="comment">#[1,3]  因为[[1,2,3]]</span></span><br></pre></td></tr></table></figure>
<h3 id="tf-boolean-mask-a-mask-axis"><a href="#tf-boolean-mask-a-mask-axis" class="headerlink" title="tf.boolean_mask(a,mask=[],axis=)"></a>tf.boolean_mask(a,mask=[],axis=)</h3><p>mask是一个布尔数组，axis默认为0，mask的形状要与轴对应，功能取出mask中True对应a位置中的元素</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a.shape         <span class="comment">#[4,28,28,3]</span></span><br><span class="line">tf.boolean_mask(a,mask=[<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>]).shape <span class="comment">#[2,28,28,3]</span></span><br><span class="line">tf.boolean_mask(a,mask=[<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">False</span>],axis=<span class="number">3</span>).shape <span class="comment">#[4,28,28,2]</span></span><br><span class="line"></span><br><span class="line">b = tf.onse([<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">tf.boolean_mask(b,mask=[[<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>],[<span class="literal">False</span>,<span class="literal">True</span>,<span class="literal">True</span>]])</span><br><span class="line">输出：</span><br><span class="line">[[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]]</span><br></pre></td></tr></table></figure>

<h2 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h2><h3 id="tf-reshape-a-b-c"><a href="#tf-reshape-a-b-c" class="headerlink" title="tf.reshape(a,[b,c])"></a>tf.reshape(a,[b,c])</h3><p>将a的形状转换为[b,c],注意这个操作不能改变a数据本身</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a =tf.random.normal([<span class="number">4</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">3</span>])</span><br><span class="line">a.shape,a.nidm        <span class="comment">#[4,28,28,3],4</span></span><br><span class="line">tf.reshape(a,[<span class="number">4</span>,<span class="number">784</span>,<span class="number">3</span>]).shape  <span class="comment">#[4,784,3]</span></span><br><span class="line">tf.reshape(a,[<span class="number">4</span>,<span class="number">-1</span>,<span class="number">3</span>]).shape   <span class="comment">#[4,784,3]  -1只能出现一次,自动帮我们计算28*28</span></span><br><span class="line">tf.reshape(a,[<span class="number">4</span>,<span class="number">784</span>*<span class="number">3</span>]).shape  <span class="comment">#[4,2352]</span></span><br><span class="line">tf.reshape(a,[<span class="number">4</span>,<span class="number">-1</span>]).shape     <span class="comment">#[4,2352]</span></span><br></pre></td></tr></table></figure>

<h3 id="tf-transpose-a-perm"><a href="#tf-transpose-a-perm" class="headerlink" title="tf.transpose(a,perm=[])"></a>tf.transpose(a,perm=[])</h3><p>可以改变a数据本身，具体操作原理见PPT，perm是用来指定顺序的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.normal([<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line">a.shape    <span class="comment">#[4,3,2,1]</span></span><br><span class="line">tf.transpose(a).shape  <span class="comment">#[1,2,3,4]</span></span><br><span class="line">tf.transpose(a,perm=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>]).shape   <span class="comment">#[4,3,1,2]</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.normal([<span class="number">4</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">3</span>])</span><br><span class="line">tf.transpose(a,[<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>]).shape   <span class="comment">#[4,28,28,3]</span></span><br><span class="line">tf.transpose(a,[<span class="number">0</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>]).shape   <span class="comment">#[4,3,28,28]</span></span><br><span class="line">tf.transpose(a,[<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>]).shape   <span class="comment">#[4,3,28,28]</span></span><br></pre></td></tr></table></figure>

<h3 id="tf-expand-dims-a-axis"><a href="#tf-expand-dims-a-axis" class="headerlink" title="tf.expand_dims(a,axis=)"></a>tf.expand_dims(a,axis=)</h3><p>在指定维度添加维度，如果给定轴是正数，则在轴之前添加，如果给定负数，在轴之后添加</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a =tf.random.normal([<span class="number">4</span>,<span class="number">35</span>,<span class="number">8</span>])</span><br><span class="line">tf.expand_dims(a,axis=<span class="number">0</span>).shape   <span class="comment">#[1,4,35,8]</span></span><br><span class="line">tf.expand_dims(a,axis=<span class="number">3</span>).shape   <span class="comment">#[4,35,8,1]</span></span><br><span class="line">tf.expand_dims(a,axis=<span class="number">-1</span>).shape  <span class="comment">#[4,35,8,1]</span></span><br><span class="line">tf.expand_dims(a,axis=<span class="number">-4</span>).shape  <span class="comment">#[1,4,35,8]</span></span><br></pre></td></tr></table></figure>

<h3 id="tf-squeeze-a"><a href="#tf-squeeze-a" class="headerlink" title="tf.squeeze(a)"></a>tf.squeeze(a)</h3><p>没有axis参数时删除a中维数为1的全部维数，也可以指定删除某个维数，只要加一个axis=即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tf.squeeze(tf.zeros([<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>])).shape   <span class="comment">#[2,3]</span></span><br><span class="line">a = tf.zeros([<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>])</span><br><span class="line">tf.squeeze(a,axis=<span class="number">0</span>).shpae  <span class="comment">#[2,1,3]</span></span><br><span class="line">tf.squeeze(a,axis=<span class="number">2</span>).shape  <span class="comment">#[1,2,3]</span></span><br><span class="line">tf.squeeze(a,axis=<span class="number">-2</span>).shape <span class="comment">#[1,2,3]</span></span><br><span class="line">tf.squeeze(a,axis=<span class="number">-4</span>).shape <span class="comment">#[2,1,3]</span></span><br></pre></td></tr></table></figure>
<h2 id="广播"><a href="#广播" class="headerlink" title="广播"></a>广播</h2><h3 id="普通例子"><a href="#普通例子" class="headerlink" title="普通例子"></a>普通例子</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>])</span><br><span class="line">(x+tf.random.normal([<span class="number">3</span>])).shape         <span class="comment">#[4,32,32,3]</span></span><br><span class="line">(x+tf.random.normal([<span class="number">32</span>,<span class="number">32</span>,<span class="number">1</span>])).shape   <span class="comment">#[4,32,32,3]</span></span><br><span class="line">(x+tf.random.normal([<span class="number">4</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>])).shape   <span class="comment">#[4,32,32,3]</span></span><br></pre></td></tr></table></figure>
<h3 id="tf-broadcast-to-a"><a href="#tf-broadcast-to-a" class="headerlink" title="tf.broadcast_to(a,[])"></a>tf.broadcast_to(a,[])</h3><p>将a广播到[]的形状，前提是a的形状与[]匹配，才可以进行广播</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x.shape        <span class="comment">#[4,32,32,3]</span></span><br><span class="line">(x+tf.random.normal([<span class="number">4</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>])).shape   <span class="comment">#[4,32,32,3]</span></span><br><span class="line">b = tf.broadcast_to(tf.random.normal([<span class="number">4</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]),[<span class="number">4</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>])</span><br><span class="line">b.shape     <span class="comment">#[4,32,32,3]</span></span><br></pre></td></tr></table></figure>
<h3 id="tf-tile-a-1-2"><a href="#tf-tile-a-1-2" class="headerlink" title="tf.tile(a,[1,2])"></a>tf.tile(a,[1,2])</h3><p>假如a是二维的，那么第0个轴复制一次，表示不变，第1个轴复制两次，变为原来两倍</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = tf.ones([<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">a1 = tf.expand_dims(a,axis=<span class="number">0</span>)   <span class="comment">#[1,3,4]</span></span><br><span class="line">a1 = tf.tile(a1,[<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>])        <span class="comment">#[2,3,4]</span></span><br></pre></td></tr></table></figure>
<h2 id="数学运算"><a href="#数学运算" class="headerlink" title="数学运算"></a>数学运算</h2><h3 id=""><a href="#" class="headerlink" title="+-*/ // %"></a>+-*/ // %</h3><p>矩阵对应元素运算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">b = tf.fill([<span class="number">2</span>,<span class="number">2</span>],<span class="number">2.</span>)</span><br><span class="line">a = tf.ones([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">a+b,a-b,a*b,a/b,b//a,b%a</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">[[<span class="number">3.</span>,<span class="number">3.</span>],</span><br><span class="line">[<span class="number">3.</span>,<span class="number">3.</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">-1.</span>,<span class="number">-1.</span>],</span><br><span class="line">[<span class="number">-1.</span>,<span class="number">-1.</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">2.</span>,<span class="number">2.</span>],</span><br><span class="line">[<span class="number">2.</span>,<span class="number">2.</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">0.5</span>,<span class="number">0.5</span>],</span><br><span class="line">[<span class="number">0.5</span>,<span class="number">0.5</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">2.</span>,<span class="number">2.</span>],</span><br><span class="line">[<span class="number">2.</span>,<span class="number">2.</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">0.</span>,<span class="number">0.</span>],</span><br><span class="line">[<span class="number">0.</span>,<span class="number">0.</span>]]</span><br></pre></td></tr></table></figure>

<h3 id="tf-pow-a-和tf-sqrt"><a href="#tf-pow-a-和tf-sqrt" class="headerlink" title="tf.pow(a) 和tf.sqrt()"></a>tf.pow(a) 和tf.sqrt()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">b = tf.fill([<span class="number">2</span>,<span class="number">2</span>],<span class="number">2.</span>)</span><br><span class="line">tf.pow(b)</span><br><span class="line">b**<span class="number">3</span></span><br><span class="line">tf.sqrt(b)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">[[<span class="number">8.</span>,<span class="number">8.</span>],</span><br><span class="line">[<span class="number">8.</span>,<span class="number">8.</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">8.</span>,<span class="number">8.</span>],</span><br><span class="line">[<span class="number">8.</span>,<span class="number">8.</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">1.414</span>,<span class="number">1.414</span>],</span><br><span class="line">[<span class="number">1.414</span>,<span class="number">1.414</span>]]</span><br></pre></td></tr></table></figure>
<h3 id="tf-math-log-和tf-exp"><a href="#tf-math-log-和tf-exp" class="headerlink" title="tf.math.log()和tf.exp()"></a>tf.math.log()和tf.exp()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">a = tf.ones([<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">tf.math.log(a)   <span class="comment">#默认以e为底</span></span><br><span class="line">tf.exp(a)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">[[<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">0</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">2.718</span>,<span class="number">2.718</span>],</span><br><span class="line">[<span class="number">2.718</span>,<span class="number">2.718</span>]]</span><br><span class="line">``` </span><br><span class="line"><span class="comment">### a@b tf.manual(a,b) </span></span><br><span class="line">矩阵相乘</span><br><span class="line">```python</span><br><span class="line">a = tf.ones([<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">b = tf.fill([<span class="number">2</span>,<span class="number">2</span>],<span class="number">2</span>)</span><br><span class="line">a@b</span><br><span class="line">tf.matual(a,b)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">[[<span class="number">4</span>,<span class="number">4</span>],</span><br><span class="line">[<span class="number">4</span>,<span class="number">4</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">4</span>,<span class="number">4</span>],</span><br><span class="line">[<span class="number">4</span>,<span class="number">4</span>]]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.ones([<span class="number">4</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">b = tf.fill([<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>],<span class="number">2</span>)   <span class="comment">#这边的4是batch,计算时其实是（2，3）@（3，5）</span></span><br><span class="line">(a@b).shape   <span class="comment">#[4,2,5]</span></span><br><span class="line">tf.matual(a,b).shape    <span class="comment">#[4,2,5]</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a.shape   <span class="comment">#[4,2,3]</span></span><br><span class="line">b.shape   <span class="comment">#[3,5]</span></span><br><span class="line">bb = tf.broadcast_to(b,[<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>])</span><br><span class="line">(a@bb).shape    <span class="comment">#[4,2,5]</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = tf.ones([<span class="number">4</span>,<span class="number">2</span>])</span><br><span class="line">W = tf.ones([<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line">b = tf.constant(<span class="number">0.1</span>)</span><br><span class="line">x@W+b</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">[[<span class="number">2.1</span>],</span><br><span class="line">[<span class="number">2.1</span>],</span><br><span class="line">[<span class="number">2.1</span>],</span><br><span class="line">[<span class="number">2.1</span>]]</span><br></pre></td></tr></table></figure>
<h1 id="tensorflow高阶操作"><a href="#tensorflow高阶操作" class="headerlink" title="tensorflow高阶操作"></a>tensorflow高阶操作</h1><h2 id="合并与分割"><a href="#合并与分割" class="headerlink" title="合并与分割"></a>合并与分割</h2><h3 id="tf-concat-a-b-axis"><a href="#tf-concat-a-b-axis" class="headerlink" title="tf.concat([a,b],axis=)"></a>tf.concat([a,b],axis=)</h3><p>在哪个轴上拼接a,b两个数组,除了拼接的那个轴外的其他维度要全部相等</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = tf.ones([<span class="number">4</span>,<span class="number">35</span>,<span class="number">8</span>])</span><br><span class="line">b = tf.ones([<span class="number">2</span>,<span class="number">35</span>,<span class="number">8</span>])</span><br><span class="line">c = tf.concat([a,b],axis=<span class="number">0</span>)</span><br><span class="line">c.shape    <span class="comment">#[6,35,8]</span></span><br><span class="line"></span><br><span class="line">a = tf.ones([<span class="number">4</span>,<span class="number">32</span>,<span class="number">8</span>])</span><br><span class="line">b = tf,ones([<span class="number">4</span>,<span class="number">3</span>,<span class="number">8</span>])</span><br><span class="line">tf.concat([a,b],axis=<span class="number">1</span>).shape   <span class="comment">#[4,35,8]</span></span><br></pre></td></tr></table></figure>
<h3 id="tf-stack-a-b-axis"><a href="#tf-stack-a-b-axis" class="headerlink" title="tf.stack([a,b],axis=)"></a>tf.stack([a,b],axis=)</h3><p>创造新的维度，然后拼接a,b</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a.shape   <span class="comment">#[4,35,8]</span></span><br><span class="line">b.shape   <span class="comment">#[4,35,8]</span></span><br><span class="line">tf.concat([a,b],axis=<span class="number">-1</span>).shape   <span class="comment">#[4,35,16]</span></span><br><span class="line">tf.stack([a,b],axis=<span class="number">0</span>).shape     <span class="comment">#[2,4,35,8]</span></span><br><span class="line">tf.stack([a,b],axis=<span class="number">3</span>).shape     <span class="comment">#[4,35,8,2]</span></span><br></pre></td></tr></table></figure>
<h3 id="tf-unstack-c-axis"><a href="#tf-unstack-c-axis" class="headerlink" title="tf.unstack(c,axis=)"></a>tf.unstack(c,axis=)</h3><p>stack的反操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a.shape     <span class="comment">#[4,35,8]</span></span><br><span class="line">b = tf.ones([<span class="number">4</span>,<span class="number">35</span>,<span class="number">8</span>])</span><br><span class="line">c = tf.stack([a,b])</span><br><span class="line">c.shape   <span class="comment">#[2,4,35,8]</span></span><br><span class="line">aa,bb = tf.unstack(c,axis=<span class="number">0</span>)</span><br><span class="line">aa.shape  <span class="comment">#[4,35,8]</span></span><br><span class="line">bb.shape  <span class="comment">#[4,35,8]</span></span><br><span class="line">res = tf.unstack(c,axis=<span class="number">3</span>)   <span class="comment">#打散成8个，这个轴上有多少就会打散成几个</span></span><br><span class="line">res[<span class="number">0</span>].shape   <span class="comment">#[2,4,35]</span></span><br><span class="line">res[<span class="number">7</span>].shape   <span class="comment">#[2,4,35]</span></span><br></pre></td></tr></table></figure>

<h3 id="tf-split-c-axis-num-or-size-splits"><a href="#tf-split-c-axis-num-or-size-splits" class="headerlink" title="tf.split(c,axis=,num_or_size_splits=[])"></a>tf.split(c,axis=,num_or_size_splits=[])</h3><p>可以指定打散后的数量和比例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#接着上面</span></span><br><span class="line">res = tf.unstack(c,axis=<span class="number">3</span>)</span><br><span class="line">len(res)   <span class="comment">#8</span></span><br><span class="line">res = tf.split(c,axis=<span class="number">8</span>,num_or_size_splits=<span class="number">2</span>) <span class="comment">#打散成两个</span></span><br><span class="line">len(res)   <span class="comment">#2</span></span><br><span class="line">res[<span class="number">0</span>].shape   <span class="comment">#[2,4,35,4]</span></span><br><span class="line">res = tf.split(c,axis=<span class="number">8</span>,num_or_size_splits=[<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>])  <span class="comment">#打散成3个，第一个2份，第二个2份，第三个4份</span></span><br><span class="line">res[<span class="number">0</span>].shape   <span class="comment">#[2,4,35,2]</span></span><br><span class="line">res[<span class="number">1</span>].shape   <span class="comment">#[2,4,35,2]</span></span><br></pre></td></tr></table></figure>

<h2 id="数据统计"><a href="#数据统计" class="headerlink" title="数据统计"></a>数据统计</h2><h3 id="tf-norm-a"><a href="#tf-norm-a" class="headerlink" title="tf.norm(a)"></a>tf.norm(a)</h3><p>默认求二范数，没有指定哪个轴，求整体的范数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = tf.ones([<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">tf.norm(a)     <span class="comment">#2</span></span><br><span class="line">tf.sqrt(tf.reduce_sum(tf.square(a)))   <span class="comment">#2</span></span><br><span class="line">a = tf.ones([<span class="number">4</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">3</span>])</span><br><span class="line">tf.norm(a)     <span class="comment">#96.99484</span></span><br><span class="line">tf.sqrt(tf.reduce_sum(tf.square(a)))   <span class="comment">#96.99484</span></span><br></pre></td></tr></table></figure>
<h3 id="tf-norm-a-ord-2-axis-1"><a href="#tf-norm-a-ord-2-axis-1" class="headerlink" title="tf.norm(a,ord=2,axis=1)"></a>tf.norm(a,ord=2,axis=1)</h3><p>求a在轴1上的二范数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">b = tf.ones([<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">tf.norm(b)   <span class="comment">#2</span></span><br><span class="line">tf.morm(b,ord=<span class="number">2</span>,axis=<span class="number">1</span>)       <span class="comment">#[1.414,1.414]在轴1上求2范数</span></span><br><span class="line">tf.norm(b,ord=<span class="number">1</span>)              <span class="comment">#4</span></span><br><span class="line">tf.norm(b,ord=<span class="number">1</span>,axis=<span class="number">0</span>)       <span class="comment">#[2,2] 在轴0上求一范数</span></span><br></pre></td></tr></table></figure>

<h3 id="tf-reduce-min-a-tf-reduce-max-a-tf-reduce-mean-a"><a href="#tf-reduce-min-a-tf-reduce-max-a-tf-reduce-mean-a" class="headerlink" title="tf.reduce_min(a),tf.reduce_max(a),tf.reduce_mean(a)"></a>tf.reduce_min(a),tf.reduce_max(a),tf.reduce_mean(a)</h3><p>不指定维度的情况下默认打散到一维</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.normal([<span class="number">4</span>,<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">tf.reduce_min(a),tf.reduce_max(a),tf.reduce_mean(a)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line"><span class="number">-1.18</span></span><br><span class="line"><span class="number">2.13</span></span><br><span class="line"><span class="number">0.35</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.normal([<span class="number">4</span>,<span class="number">10</span>])</span><br><span class="line">tf.reduce_min(a,axis=<span class="number">1</span>),tf.reduce_max(a,axis=<span class="number">1</span>),tf.reduce_mean(a,axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#指定维度</span></span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">[x,x,x,x]  四个数字</span><br><span class="line">[x,x,x,x]</span><br><span class="line">[x,x,x,x]</span><br></pre></td></tr></table></figure>

<h3 id="tf-argmax-a-tf-argmin-a"><a href="#tf-argmax-a-tf-argmin-a" class="headerlink" title="tf.argmax(a),tf.argmin(a)"></a>tf.argmax(a),tf.argmin(a)</h3><p>默认axis=0,若a.shape=([4,10])，输出(10,)数组</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a.shape   <span class="comment">#[4,10]</span></span><br><span class="line">tf.argmax(a).shape   <span class="comment">#[10]</span></span><br><span class="line">tf.argmin(a).shape   <span class="comment">#[10]</span></span><br></pre></td></tr></table></figure>
<h3 id="tf-equal-a-b"><a href="#tf-equal-a-b" class="headerlink" title="tf.equal(a,b)"></a>tf.equal(a,b)</h3><p>看两个数组是否相等，输出为a(a,b形状相同)的形状的数组，相同元素位置为True,不同则为False</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">b = tf.range(<span class="number">5</span>)</span><br><span class="line">tf.equal(a,b)    <span class="comment">#[False,False,False,False,False]</span></span><br><span class="line">tf.reduce_sum(tf.cast(res,dtype=int32))   <span class="comment">#0</span></span><br></pre></td></tr></table></figure>

<h3 id="accuracy计算方法见ppt"><a href="#accuracy计算方法见ppt" class="headerlink" title="accuracy计算方法见ppt"></a>accuracy计算方法见ppt</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([[<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.7</span>],</span><br><span class="line">	[<span class="number">0.9</span>,<span class="number">.005</span>,<span class="number">0.05</span>]])</span><br><span class="line">pred = tf.cast(tf.argmax(a,axis=<span class="number">1</span>),dtype=int32)   <span class="comment">#[2,1]</span></span><br><span class="line">y    <span class="comment">#[2,1]</span></span><br><span class="line">tf.equal(y,pred)  <span class="comment">#[True,False]</span></span><br><span class="line">correct = tf.reduce_sum(tf.cast(tf.equal(y,pred),dtype=int32))</span><br><span class="line">correct     <span class="comment">#1  这两组数据中只有一个相等</span></span><br><span class="line">correct/<span class="number">2</span>   <span class="comment">#0.5  </span></span><br><span class="line"><span class="comment">#结合实例理解这个</span></span><br></pre></td></tr></table></figure>
<h3 id="tf-unique-a"><a href="#tf-unique-a" class="headerlink" title="tf.unique(a)"></a>tf.unique(a)</h3><p>去除a中相同元素，输出两个数组，第一个数去重后的数组，第二个是索引数组</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="number">4</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">3</span>])</span><br><span class="line">tf.unique(a)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">unique=[<span class="number">4</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">idx=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>]   <span class="comment">#这个索引是[4,2,3],所以可以根据tf.gather(unique,idx)还原</span></span><br></pre></td></tr></table></figure>


<h2 id="张量排序"><a href="#张量排序" class="headerlink" title="张量排序"></a>张量排序</h2><h3 id="tf-random-shuttle-tf-range-5"><a href="#tf-random-shuttle-tf-range-5" class="headerlink" title="tf.random.shuttle(tf.range(5))"></a>tf.random.shuttle(tf.range(5))</h3><p>随机打散</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.random.shuttle(tf.range(<span class="number">5</span>))    <span class="comment">#[2,0,3,4,1]</span></span><br></pre></td></tr></table></figure>
<h3 id="tf-sort-a-direction-”DESCENDING”"><a href="#tf-sort-a-direction-”DESCENDING”" class="headerlink" title="tf.sort(a,direction=”DESCENDING”)"></a>tf.sort(a,direction=”DESCENDING”)</h3><p>将a进行降序</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.shuttle(tf.range(<span class="number">5</span>)) <span class="comment">#[2,0,3,4,1]</span></span><br><span class="line">tf.sort(a,direction=<span class="string">"DESCENDING"</span>)  <span class="comment">#[4,3,2,1,0]</span></span><br></pre></td></tr></table></figure>
<h3 id="tf-argsort-a-direction-”DESCENDING”"><a href="#tf-argsort-a-direction-”DESCENDING”" class="headerlink" title="tf.argsort(a,direction=”DESCENDING”)"></a>tf.argsort(a,direction=”DESCENDING”)</h3><p>返回排序后每个元素在以前数组中的位置索引数组，第一个元素是最大值在以前数组的索引</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tf.argsort(a,direction=<span class="string">"DESCENDING"</span>)    [<span class="number">3</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">4</span>,<span class="number">1</span>]</span><br><span class="line">idx = tf.argsort(a,direction=<span class="string">"DESCENDING"</span>)</span><br><span class="line">tf.gather(a,idx)   <span class="comment">#这样可以实现tf.sort功能</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.uniform([<span class="number">3</span>,<span class="number">3</span>],maxval=<span class="number">10</span>,dtype=tf.int32)</span><br><span class="line">[[<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>],</span><br><span class="line">[<span class="number">9</span>,<span class="number">4</span>,<span class="number">7</span>],</span><br><span class="line">[<span class="number">4</span>,<span class="number">5</span>,<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">tf.sort(a)</span><br><span class="line">[[<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>],</span><br><span class="line">[<span class="number">4</span>,<span class="number">7</span>,<span class="number">9</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">4</span>,<span class="number">5</span>]]</span><br><span class="line"></span><br><span class="line">tf.sort(a,direction=<span class="string">"DESCENDING"</span>)</span><br><span class="line">[[<span class="number">8</span>,<span class="number">6</span>,<span class="number">4</span>],</span><br><span class="line">[<span class="number">9</span>,<span class="number">7</span>,<span class="number">4</span>],</span><br><span class="line">[<span class="number">5</span>,<span class="number">4</span>,<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">idx = tf.argsort(a)</span><br><span class="line">[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>]]</span><br></pre></td></tr></table></figure>
<h3 id="res-tf-math-top-k-a-2"><a href="#res-tf-math-top-k-a-2" class="headerlink" title="res=tf.math.top_k(a,2)"></a>res=tf.math.top_k(a,2)</h3><p>寻找最大值以及次大值和他们的索引，返回两个数组</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">a</span><br><span class="line">[[<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>],</span><br><span class="line">[<span class="number">9</span>,<span class="number">4</span>,<span class="number">7</span>],</span><br><span class="line">[<span class="number">4</span>,<span class="number">5</span>,<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">res = tf.math.top_k(a,<span class="number">2</span>)  <span class="comment">#寻找最大值和次高值以及他们的索引</span></span><br><span class="line">res.indices</span><br><span class="line">[[<span class="number">2</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">0</span>]]</span><br><span class="line"></span><br><span class="line">res.values</span><br><span class="line">[[<span class="number">8</span>,<span class="number">6</span>],</span><br><span class="line">[<span class="number">9</span>,<span class="number">7</span>],</span><br><span class="line">[<span class="number">5</span>,<span class="number">4</span>]]</span><br></pre></td></tr></table></figure>

<h3 id="TOP-K-accuracy见ppt"><a href="#TOP-K-accuracy见ppt" class="headerlink" title="TOP_K accuracy见ppt"></a>TOP_K accuracy见ppt</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">prob = tf.constant([[<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.7</span>],[<span class="number">0.2</span>,<span class="number">0.7</span>,<span class="number">0.1</span>]])   </span><br><span class="line"><span class="comment">#[0.1,0.2,0.7]第一个样本的预测概率，2的概率最大</span></span><br><span class="line"><span class="comment">#[0.2,0.7,0.1]第二个样本的预测概率，1的概率最大</span></span><br><span class="line">k_b = tf.math.top_k(prob,<span class="number">3</span>).indices</span><br><span class="line">[[<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>]]</span><br><span class="line"></span><br><span class="line">k_b = tf.transpose(k_b,[<span class="number">1</span>,<span class="number">0</span>])</span><br><span class="line">[[<span class="number">2</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">2</span>,<span class="number">0</span>]]</span><br><span class="line"></span><br><span class="line">target = tf.constant([<span class="number">2</span>,<span class="number">0</span>])</span><br><span class="line">target = tf.broadcast_to(target,[<span class="number">3</span>,<span class="number">2</span>])</span><br><span class="line">[[<span class="number">2</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">2</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">2</span>,<span class="number">0</span>]]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span><span class="params">(output,target,topk=<span class="params">(<span class="number">1</span>,)</span>)</span>:</span>    </span><br><span class="line"><span class="comment">#这个topk是自定义的，你想求到top几就写到几，比如想求到top3就写为（1，2，3）</span></span><br><span class="line">	maxk = max(topk)</span><br><span class="line">	batch_size = target.shape[<span class="number">0</span>]   <span class="comment">#一共有几个样本</span></span><br><span class="line">	pred = tf.math.top_k(output,maxk).indices</span><br><span class="line">	pred = tf.transpose(pred,[<span class="number">1</span>,<span class="number">0</span>])</span><br><span class="line">	target_ = tf.broadcast_to(target,pred.shape)</span><br><span class="line">	correct = tf.equal(pred,target_)</span><br><span class="line"></span><br><span class="line">	res = []</span><br><span class="line">	<span class="keyword">for</span> k <span class="keyword">in</span> topk:</span><br><span class="line">		correct_k = tf.cast(tf.reshape(correct[:k],[<span class="number">-1</span>]),dtype=tf.int32)</span><br><span class="line">		correct_k = tf.reduce_sum(correct_k)</span><br><span class="line">		acc = float(correct_k/batch_size)</span><br><span class="line">		res.append(acc)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">a = tf,constant([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line">b = reshape(a[:<span class="number">2</span>],[<span class="number">-1</span>])</span><br><span class="line">[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">a[:<span class="number">2</span>]</span><br><span class="line">[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]]</span><br><span class="line"></span><br><span class="line">a[:<span class="number">2</span>][<span class="number">0</span>]   <span class="comment">#取a[:2]的第0个</span></span><br><span class="line">[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">a[:<span class="number">2</span>,<span class="number">0</span>]    <span class="comment">#遍历前两行，取第0个元素</span></span><br><span class="line">[<span class="number">1</span>,<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h2 id="填充和复制"><a href="#填充和复制" class="headerlink" title="填充和复制"></a>填充和复制</h2><h3 id="tf-pad-a-0-0-0-0-不填充"><a href="#tf-pad-a-0-0-0-0-不填充" class="headerlink" title="tf.pad(a,[[0,0],[0,0]]) 不填充"></a>tf.pad(a,[[0,0],[0,0]]) 不填充</h3><p>在行上面填充一行，默认用0填充</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">a = tf.reshape(tf.range(<span class="number">9</span>),[<span class="number">3</span>,<span class="number">3</span>])</span><br><span class="line">[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]]</span><br><span class="line"></span><br><span class="line">tf.pad(a,[[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0</span>]])  <span class="comment">#不填充</span></span><br><span class="line">[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]]</span><br><span class="line"></span><br><span class="line">tf.pad(a,[[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0</span>]])   <span class="comment">#在行上面填充一行</span></span><br><span class="line">[[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]]</span><br><span class="line"></span><br><span class="line">tf.pad(a,[[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">0</span>]])</span><br><span class="line">[[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]]</span><br><span class="line"></span><br><span class="line">tf.pad(a,[[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">0</span>]])</span><br><span class="line">[[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]]</span><br><span class="line"></span><br><span class="line">tf.pad(a,[[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line">[[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#图片填充</span></span><br><span class="line">a = tf.random.normal([<span class="number">4</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">3</span>])    <span class="comment">#四张28*28三通道照片</span></span><br><span class="line">b = tf.pad(a,[[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">2</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">2</span>],[<span class="number">0</span>,<span class="number">0</span>]])</span><br><span class="line">b.shape   <span class="comment">#[4,32,32,3]</span></span><br><span class="line"><span class="comment">#每张照片的上下左右分别填充1行（列），照片数量和通道数没有改变</span></span><br></pre></td></tr></table></figure>
<h3 id="tf-tile"><a href="#tf-tile" class="headerlink" title="tf.tile()"></a>tf.tile()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">a</span><br><span class="line">[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]]</span><br><span class="line"></span><br><span class="line">tf.tile(a,[<span class="number">1</span>,<span class="number">2</span>])  <span class="comment">#1代表对应的轴不复制，2代表对应的轴复制两次</span></span><br><span class="line">[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]]</span><br><span class="line"></span><br><span class="line">tf.tile(a,[<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line">[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]]</span><br><span class="line"></span><br><span class="line">tf.tile(a,[<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]]</span><br><span class="line"></span><br><span class="line">aa = tf.expand_dims(a,axis=<span class="number">0</span>)</span><br><span class="line">[[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]]]</span><br><span class="line"></span><br><span class="line">tf.tile(aa,[<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">[[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]],</span><br><span class="line"></span><br><span class="line">[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]]]</span><br><span class="line"></span><br><span class="line">tf.broadcast_to(aa,[<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>])</span><br><span class="line">[[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]],</span><br><span class="line"></span><br><span class="line">[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]]]</span><br></pre></td></tr></table></figure>

<h2 id="张量和限幅"><a href="#张量和限幅" class="headerlink" title="张量和限幅"></a>张量和限幅</h2><h3 id="tf-maximum-a-2"><a href="#tf-maximum-a-2" class="headerlink" title="tf.maximum(a,2)"></a>tf.maximum(a,2)</h3><p>把a中比2小的元素用2替换掉</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>])</span><br><span class="line">tf.maximum(a,<span class="number">2</span>)    <span class="comment">#[2,2,2,3,4,5,6,7,8,9]</span></span><br></pre></td></tr></table></figure>
<h3 id="tf-minimum-a-8"><a href="#tf-minimum-a-8" class="headerlink" title="tf.minimum(a,8)"></a>tf.minimum(a,8)</h3><p>把a中比8大的元素用8换掉</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>])</span><br><span class="line">tf.minimum(a,<span class="number">8</span>)   <span class="comment">#[0,1,2,3,4,5,6,7,8,8]</span></span><br></pre></td></tr></table></figure>
<h3 id="tf-clip-by-value-a-2-8"><a href="#tf-clip-by-value-a-2-8" class="headerlink" title="tf.clip_by_value(a,2,8)"></a>tf.clip_by_value(a,2,8)</h3><p>效果是上面两个相结合</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>])</span><br><span class="line">tf.clip_by_value(a,<span class="number">2</span>,<span class="number">8</span>)   <span class="comment">#[2,2,2,3,4,5,6,7,8,8]</span></span><br></pre></td></tr></table></figure>
<h3 id="tf-nn-relu-a"><a href="#tf-nn-relu-a" class="headerlink" title="tf.nn.relu(a)"></a>tf.nn.relu(a)</h3><p>实现relu函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>])</span><br><span class="line">a = a<span class="number">-5</span>  <span class="comment">#[-5,-4,-3,-2,-1,0,1,2,3,4]</span></span><br><span class="line">tf.nn.relu(a)   <span class="comment">#[0,0,0,0,0,0,1,2,3,4]</span></span><br><span class="line">tf.maximum(a,<span class="number">0</span>) <span class="comment">#[0,0,0,0,0,0,1,2,3,4]</span></span><br></pre></td></tr></table></figure>

<h3 id="tf-clip-by-norm-a-15"><a href="#tf-clip-by-norm-a-15" class="headerlink" title="tf.clip_by_norm(a,15)"></a>tf.clip_by_norm(a,15)</h3><p>将a的二范数（a的模）放缩到15，效果是不改变a方向条件下改变a的模长</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.normal([<span class="number">2</span>,<span class="number">2</span>],mean=<span class="number">10</span>)</span><br><span class="line">[[<span class="number">12.217</span>,<span class="number">10.149</span>],</span><br><span class="line">[<span class="number">10.846</span>,<span class="number">10.972</span>]]</span><br><span class="line"></span><br><span class="line">tf.norm(a)   <span class="comment">#22.143</span></span><br><span class="line"></span><br><span class="line">aa = tf.clip_by_norm(a,<span class="number">15</span>)  </span><br><span class="line">[[<span class="number">8.276</span>,<span class="number">6.875</span>],</span><br><span class="line">[<span class="number">7.347</span>,<span class="number">7.432</span>]]</span><br><span class="line"></span><br><span class="line">tf.norm(aa)   <span class="comment">#15</span></span><br></pre></td></tr></table></figure>

<h3 id="new-grads-total-norm-tf-clip-by-global-norm-grads-25"><a href="#new-grads-total-norm-tf-clip-by-global-norm-grads-25" class="headerlink" title="new_grads,total_norm = tf.clip_by_global_norm(grads,25)"></a>new_grads,total_norm = tf.clip_by_global_norm(grads,25)</h3><p>25为设定修改后w整体的二范数</p>
<h2 id="高阶特性"><a href="#高阶特性" class="headerlink" title="高阶特性"></a>高阶特性</h2><h3 id="tf-boolean-mask"><a href="#tf-boolean-mask" class="headerlink" title="tf.boolean_mask"></a>tf.boolean_mask</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.morm([<span class="number">3</span>,<span class="number">3</span>])</span><br><span class="line">[[<span class="number">1.62</span>,<span class="number">0.439</span>,<span class="number">-0.318</span>],</span><br><span class="line">[<span class="number">1.14</span>,<span class="number">-0.024</span>,<span class="number">-0.957</span>],</span><br><span class="line">[<span class="number">1.593</span>,<span class="number">0.118</span>,<span class="number">-0.399</span>]]</span><br><span class="line"></span><br><span class="line">mask = a&gt;<span class="number">0</span></span><br><span class="line">[[<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">False</span>],</span><br><span class="line">[<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>],</span><br><span class="line">[<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">False</span>]]</span><br><span class="line"></span><br><span class="line">tf.boolean_mask(a,mask)</span><br><span class="line">[<span class="number">1.62</span>,<span class="number">0.493</span>,<span class="number">1.14</span>,<span class="number">1.593</span>,<span class="number">0.118</span>]</span><br><span class="line"></span><br><span class="line">indices = tf.where(mask)   <span class="comment">#返回mask中True的坐标</span></span><br><span class="line">[[<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">2</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">2</span>,<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">tf.gather_nd(a,indices)</span><br><span class="line">[<span class="number">1.62</span>,<span class="number">0.493</span>,<span class="number">1.14</span>,<span class="number">1.593</span>,<span class="number">0.118</span>]</span><br></pre></td></tr></table></figure>
<h3 id="tf-where-mask-a-b"><a href="#tf-where-mask-a-b" class="headerlink" title="tf.where(mask,a,b)"></a>tf.where(mask,a,b)</h3><p>mask,a,b形状要相同，如果mask中某个位置元素为True,那么这个位置选a所在这个位置的元素，如果是False,选b的值 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mask</span><br><span class="line">[[<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">False</span>],</span><br><span class="line">[<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>],</span><br><span class="line">[<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">False</span>]]</span><br><span class="line"></span><br><span class="line">A = tf.ones([<span class="number">3</span>,<span class="number">3</span>])</span><br><span class="line">B = tf.zeros([<span class="number">3</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">tf.where(mask,A,B)</span><br><span class="line">[[<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>]]</span><br></pre></td></tr></table></figure>
<h3 id="tf-scatter-nd"><a href="#tf-scatter-nd" class="headerlink" title="tf.scatter_nd()"></a>tf.scatter_nd()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">indices = tf.constant([[<span class="number">4</span>],[<span class="number">3</span>],[<span class="number">1</span>],[<span class="number">7</span>]])</span><br><span class="line">updates = tf.sonstant([<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>])</span><br><span class="line">shape = tf.constant([<span class="number">8</span>])   <span class="comment">#产生维度为（8，）的全0底板</span></span><br><span class="line">tf.scatter_nd(indices,updates,shape)</span><br><span class="line">[<span class="number">0</span>,<span class="number">11</span>,<span class="number">0</span>,<span class="number">10</span>,<span class="number">9</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">12</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">indices = tf.constant([[<span class="number">0</span>],[<span class="number">2</span>]])</span><br><span class="line">updates = tf.constant([</span><br><span class="line">	[[<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>],[<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>],</span><br><span class="line">	[<span class="number">7</span>,<span class="number">7</span>,<span class="number">7</span>,<span class="number">7</span>],[<span class="number">8</span>,<span class="number">8</span>,<span class="number">8</span>,<span class="number">8</span>]],</span><br><span class="line"></span><br><span class="line">	[[<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>],[<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>],</span><br><span class="line">	[<span class="number">7</span>,<span class="number">7</span>,<span class="number">7</span>,<span class="number">7</span>],[<span class="number">8</span>,<span class="number">8</span>,<span class="number">8</span>,<span class="number">8</span>]]])</span><br><span class="line">updates.shape   <span class="comment">#(2,4,4)</span></span><br><span class="line">shape = tf.constant([<span class="number">4</span>,<span class="number">4</span>,<span class="number">4</span>])</span><br><span class="line">tf.scatter_nd(indices,updates,shape)</span><br><span class="line">[[[<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>],</span><br><span class="line">  [<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>],</span><br><span class="line">  [<span class="number">7</span>,<span class="number">7</span>,<span class="number">7</span>,<span class="number">7</span>],</span><br><span class="line">  [<span class="number">8</span>,<span class="number">8</span>,<span class="number">8</span>,<span class="number">8</span>]],</span><br><span class="line"></span><br><span class="line"> [[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">  [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">  [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">  [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]],</span><br><span class="line"></span><br><span class="line"> [[<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>],</span><br><span class="line">  [<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>],</span><br><span class="line">  [<span class="number">7</span>,<span class="number">7</span>,<span class="number">7</span>,<span class="number">7</span>],</span><br><span class="line">  [<span class="number">8</span>,<span class="number">8</span>,<span class="number">8</span>,<span class="number">8</span>]],</span><br><span class="line"></span><br><span class="line"> [[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">  [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">  [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">  [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]]]</span><br></pre></td></tr></table></figure>
<h3 id="tf-meshgrid"><a href="#tf-meshgrid" class="headerlink" title="tf.meshgrid()"></a>tf.meshgrid()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">y = tf.linspace(<span class="number">-2</span>,<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">x = tf.linspace(<span class="number">-2</span>,<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">points_x,points_y = tf.meshgrid(x,y)   </span><br><span class="line"><span class="comment">#相当于形成25个点，将这些点的两个坐标拆开放在两个tensor中</span></span><br><span class="line">points_x.shape   <span class="comment">#[5,5]</span></span><br><span class="line">points_x</span><br><span class="line">[[<span class="number">-2</span>,<span class="number">-1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line"> [<span class="number">-2</span>,<span class="number">-1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line"> [<span class="number">-2</span>,<span class="number">-1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line"> [<span class="number">-2</span>,<span class="number">-1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line"> [<span class="number">-2</span>,<span class="number">-1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]]</span><br><span class="line"></span><br><span class="line">points_y</span><br><span class="line">[[<span class="number">-2</span>,<span class="number">-2</span>,<span class="number">-2</span>,<span class="number">-2</span>,<span class="number">-2</span>],</span><br><span class="line"> [<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">-1</span>],</span><br><span class="line"> [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line"> [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line"> [<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]]</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Tensorflow/" rel="tag"># Tensorflow</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/03/11/%E6%A8%A1%E7%B3%8A%E6%93%8D%E4%BD%9C%E5%92%8CEPF%E5%92%8C%E7%9B%B4%E6%96%B9%E5%9B%BE/" rel="prev" title="模糊操作和EPF和直方图">
      <i class="fa fa-chevron-left"></i> 模糊操作和EPF和直方图
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/04/01/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%ABdense%E5%AE%9E%E6%88%98/" rel="next" title="手写数字识别dense实战">
      手写数字识别dense实战 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Tensorflow基础操作"><span class="nav-number">1.</span> <span class="nav-text">Tensorflow基础操作</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#创建tensor"><span class="nav-number">1.1.</span> <span class="nav-text">创建tensor</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-convert-to-tensor-将其他类型数据转换为tensor类型"><span class="nav-number">1.1.1.</span> <span class="nav-text">tf.convert_to_tensor()  将其他类型数据转换为tensor类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-zeros"><span class="nav-number">1.1.2.</span> <span class="nav-text">tf.zeros([])</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-zeros-like-a"><span class="nav-number">1.1.3.</span> <span class="nav-text">tf.zeros_like(a)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-ones"><span class="nav-number">1.1.4.</span> <span class="nav-text">tf.ones([])</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-ones-like-a"><span class="nav-number">1.1.5.</span> <span class="nav-text">tf.ones_like(a)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-fill-a"><span class="nav-number">1.1.6.</span> <span class="nav-text">tf.fill([],a)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-random-normal-mean-stddev-正太分布"><span class="nav-number">1.1.7.</span> <span class="nav-text">tf.random.normal([],mean&#x3D;,stddev&#x3D;)  正太分布</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-random-truncated-normal-mean-stddev"><span class="nav-number">1.1.8.</span> <span class="nav-text">tf.random.truncated_normal([],mean&#x3D;,stddev&#x3D;)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-random-uniform-minval-maxval"><span class="nav-number">1.1.9.</span> <span class="nav-text">tf.random.uniform([],minval&#x3D;,maxval&#x3D;)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-random-shuttle"><span class="nav-number">1.1.10.</span> <span class="nav-text">tf.random.shuttle([])</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-gather-a-idx"><span class="nav-number">1.1.11.</span> <span class="nav-text">tf.gather(a,idx)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-one-hot-y-depth"><span class="nav-number">1.1.12.</span> <span class="nav-text">tf.one_hot(y,depth&#x3D;)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-keras-losses-mse-y-out"><span class="nav-number">1.1.13.</span> <span class="nav-text">tf.keras.losses.mse(y,out)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-reduce-mean"><span class="nav-number">1.1.14.</span> <span class="nav-text">tf.reduce_mean()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#net-layers-Dense-10"><span class="nav-number">1.1.15.</span> <span class="nav-text">net.layers.Dense(10)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#net-build"><span class="nav-number">1.1.16.</span> <span class="nav-text">net.build([])</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#net-kernel"><span class="nav-number">1.1.17.</span> <span class="nav-text">net.kernel</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#net-bias"><span class="nav-number">1.1.18.</span> <span class="nav-text">net.bias</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#索引和切片"><span class="nav-number">1.2.</span> <span class="nav-text">索引和切片</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#普通用法"><span class="nav-number">1.2.1.</span> <span class="nav-text">普通用法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#用法"><span class="nav-number">1.2.2.</span> <span class="nav-text">:用法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#：用法"><span class="nav-number">1.2.3.</span> <span class="nav-text">：用法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#…用法"><span class="nav-number">1.2.4.</span> <span class="nav-text">…用法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-gather-a-axis-d-indices-b-c-选取第d个维度，然后把这个维度中的第b-c个vector抽取出来，只能对一个维度进行操作"><span class="nav-number">1.2.5.</span> <span class="nav-text">tf.gather(a,axis&#x3D;d,indices&#x3D;[b,c]) 选取第d个维度，然后把这个维度中的第b,c个vector抽取出来，只能对一个维度进行操作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-gather-nd-a"><span class="nav-number">1.2.6.</span> <span class="nav-text">tf.gather_nd(a,[[],[],[]])</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-boolean-mask-a-mask-axis"><span class="nav-number">1.2.7.</span> <span class="nav-text">tf.boolean_mask(a,mask&#x3D;[],axis&#x3D;)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#维度变换"><span class="nav-number">1.3.</span> <span class="nav-text">维度变换</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-reshape-a-b-c"><span class="nav-number">1.3.1.</span> <span class="nav-text">tf.reshape(a,[b,c])</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-transpose-a-perm"><span class="nav-number">1.3.2.</span> <span class="nav-text">tf.transpose(a,perm&#x3D;[])</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-expand-dims-a-axis"><span class="nav-number">1.3.3.</span> <span class="nav-text">tf.expand_dims(a,axis&#x3D;)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-squeeze-a"><span class="nav-number">1.3.4.</span> <span class="nav-text">tf.squeeze(a)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#广播"><span class="nav-number">1.4.</span> <span class="nav-text">广播</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#普通例子"><span class="nav-number">1.4.1.</span> <span class="nav-text">普通例子</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-broadcast-to-a"><span class="nav-number">1.4.2.</span> <span class="nav-text">tf.broadcast_to(a,[])</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-tile-a-1-2"><span class="nav-number">1.4.3.</span> <span class="nav-text">tf.tile(a,[1,2])</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数学运算"><span class="nav-number">1.5.</span> <span class="nav-text">数学运算</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#null"><span class="nav-number">1.5.1.</span> <span class="nav-text">+-*&#x2F; &#x2F;&#x2F; %</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-pow-a-和tf-sqrt"><span class="nav-number">1.5.2.</span> <span class="nav-text">tf.pow(a) 和tf.sqrt()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-math-log-和tf-exp"><span class="nav-number">1.5.3.</span> <span class="nav-text">tf.math.log()和tf.exp()</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#tensorflow高阶操作"><span class="nav-number">2.</span> <span class="nav-text">tensorflow高阶操作</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#合并与分割"><span class="nav-number">2.1.</span> <span class="nav-text">合并与分割</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-concat-a-b-axis"><span class="nav-number">2.1.1.</span> <span class="nav-text">tf.concat([a,b],axis&#x3D;)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-stack-a-b-axis"><span class="nav-number">2.1.2.</span> <span class="nav-text">tf.stack([a,b],axis&#x3D;)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-unstack-c-axis"><span class="nav-number">2.1.3.</span> <span class="nav-text">tf.unstack(c,axis&#x3D;)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-split-c-axis-num-or-size-splits"><span class="nav-number">2.1.4.</span> <span class="nav-text">tf.split(c,axis&#x3D;,num_or_size_splits&#x3D;[])</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据统计"><span class="nav-number">2.2.</span> <span class="nav-text">数据统计</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-norm-a"><span class="nav-number">2.2.1.</span> <span class="nav-text">tf.norm(a)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-norm-a-ord-2-axis-1"><span class="nav-number">2.2.2.</span> <span class="nav-text">tf.norm(a,ord&#x3D;2,axis&#x3D;1)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-reduce-min-a-tf-reduce-max-a-tf-reduce-mean-a"><span class="nav-number">2.2.3.</span> <span class="nav-text">tf.reduce_min(a),tf.reduce_max(a),tf.reduce_mean(a)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-argmax-a-tf-argmin-a"><span class="nav-number">2.2.4.</span> <span class="nav-text">tf.argmax(a),tf.argmin(a)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-equal-a-b"><span class="nav-number">2.2.5.</span> <span class="nav-text">tf.equal(a,b)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#accuracy计算方法见ppt"><span class="nav-number">2.2.6.</span> <span class="nav-text">accuracy计算方法见ppt</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-unique-a"><span class="nav-number">2.2.7.</span> <span class="nav-text">tf.unique(a)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#张量排序"><span class="nav-number">2.3.</span> <span class="nav-text">张量排序</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-random-shuttle-tf-range-5"><span class="nav-number">2.3.1.</span> <span class="nav-text">tf.random.shuttle(tf.range(5))</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-sort-a-direction-”DESCENDING”"><span class="nav-number">2.3.2.</span> <span class="nav-text">tf.sort(a,direction&#x3D;”DESCENDING”)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-argsort-a-direction-”DESCENDING”"><span class="nav-number">2.3.3.</span> <span class="nav-text">tf.argsort(a,direction&#x3D;”DESCENDING”)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#res-tf-math-top-k-a-2"><span class="nav-number">2.3.4.</span> <span class="nav-text">res&#x3D;tf.math.top_k(a,2)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TOP-K-accuracy见ppt"><span class="nav-number">2.3.5.</span> <span class="nav-text">TOP_K accuracy见ppt</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#填充和复制"><span class="nav-number">2.4.</span> <span class="nav-text">填充和复制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-pad-a-0-0-0-0-不填充"><span class="nav-number">2.4.1.</span> <span class="nav-text">tf.pad(a,[[0,0],[0,0]]) 不填充</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-tile"><span class="nav-number">2.4.2.</span> <span class="nav-text">tf.tile()</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#张量和限幅"><span class="nav-number">2.5.</span> <span class="nav-text">张量和限幅</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-maximum-a-2"><span class="nav-number">2.5.1.</span> <span class="nav-text">tf.maximum(a,2)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-minimum-a-8"><span class="nav-number">2.5.2.</span> <span class="nav-text">tf.minimum(a,8)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-clip-by-value-a-2-8"><span class="nav-number">2.5.3.</span> <span class="nav-text">tf.clip_by_value(a,2,8)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-nn-relu-a"><span class="nav-number">2.5.4.</span> <span class="nav-text">tf.nn.relu(a)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-clip-by-norm-a-15"><span class="nav-number">2.5.5.</span> <span class="nav-text">tf.clip_by_norm(a,15)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#new-grads-total-norm-tf-clip-by-global-norm-grads-25"><span class="nav-number">2.5.6.</span> <span class="nav-text">new_grads,total_norm &#x3D; tf.clip_by_global_norm(grads,25)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#高阶特性"><span class="nav-number">2.6.</span> <span class="nav-text">高阶特性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-boolean-mask"><span class="nav-number">2.6.1.</span> <span class="nav-text">tf.boolean_mask</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-where-mask-a-b"><span class="nav-number">2.6.2.</span> <span class="nav-text">tf.where(mask,a,b)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-scatter-nd"><span class="nav-number">2.6.3.</span> <span class="nav-text">tf.scatter_nd()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-meshgrid"><span class="nav-number">2.6.4.</span> <span class="nav-text">tf.meshgrid()</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="徐志强"
      src="https://raw.githubusercontent.com/xeon76/picture/xeon76-patch-1/nier.jpg">
  <p class="site-author-name" itemprop="name">徐志强</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">25</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/xeon76" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;xeon76" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.bilibili.com/" title="https:&#x2F;&#x2F;www.bilibili.com&#x2F;" rel="noopener" target="_blank">哔哩哔哩</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">徐志强</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.6.0
  </div>

        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/three-waves.min.js"></script>


  















  

  

</body>
</html>
